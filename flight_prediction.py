# -*- coding: utf-8 -*-
"""Flight_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1a1WzsSpkS019cbMTCOB4fhmWb-d0HfKS
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()

df = pd.read_excel(r'Data_Train.xlsx')

df.head()

df.describe()

df.info()

df.isnull().sum()

df = df.dropna()

df.shape

df['Journey_Day'] = pd.to_datetime(df.Date_of_Journey,format = '%d/%m/%Y').dt.day

df['Journey_Month'] = pd.to_datetime(df['Date_of_Journey'], format = '%d/%m/%Y').dt.month

df.head()

df = df.drop(['Date_of_Journey'],axis = 1)

df['dep_hour'] = pd.to_datetime(df['Dep_Time']).dt.hour

df['dep_min'] = pd.to_datetime(df['Dep_Time']).dt.minute

df = df.drop(['Dep_Time'],axis = 1)

df.head()

df['Arrival_hour'] = pd.to_datetime(df['Arrival_Time']).dt.hour

df['Arrival_min'] = pd.to_datetime(df['Arrival_Time']).dt.minute

df = df.drop(['Arrival_Time'], axis = 1)

#Dealing with Duration
duration = list(df['Duration'])

for i in range(len(duration)):
  if len(duration[i].split())!=2:
    if 'h' in duration[i]:
      duration[i] = duration[i].strip() +' 0m'
    else:
      duration[i] = '0h '+ duration[i]  
dur_hour = []
dur_min = [] 
for i in range(len(duration)):
  dur_hour.append(int(duration[i].split(sep = 'h')[0]))
  dur_min.append(int(duration[i].split(sep = 'm')[0].split()[-1]))

df['dur_hour'] = dur_hour
df['dur_min'] = dur_min

df.head()

df = df.drop(['Duration'],axis = 1)

#Dealing Categorical features
df['Airline'].value_counts()

sns.catplot(x = 'Airline', y = 'Price', data = df.sort_values('Price', ascending = False),kind = 'boxen', height = 6, aspect=3)
plt.show()

Airline = pd.get_dummies(df['Airline'], drop_first= True)

Airline.head()

df['Source'].value_counts()

sns.catplot(x = 'Source', y = 'Price', data = df.sort_values('Price', ascending = False),kind = 'boxen', height = 6, aspect=3)
plt.show()

Source = df[['Source']]
Source = pd.get_dummies(Source, drop_first= True)

Source.head()

df['Destination'].value_counts()

Destination = df[['Destination']]
Destination = pd.get_dummies(Destination, drop_first= True)

Destination.head()

df = df.drop(['Route', 'Additional_Info'], axis = 1)

df.head()

df['Total_Stops'].value_counts()

df.replace({'non-stop':0, '1 stop': 1, '2 stops': 2, '3 stops': 3, '4 stops': 4},inplace = True)

df.head()

data_train = pd.concat([df,Airline,Source,Destination], axis = 1)

data_train.head()

data_train.drop(['Airline','Source','Destination'],axis = 1, inplace= True)

data_train.head()

data_train.shape

"""Test Data"""

test = pd.read_excel(r'Test_set.xlsx')

test.head()

test.isnull().sum()

test['Journey_Day'] = pd.to_datetime(test.Date_of_Journey,format = '%d/%m/%Y').dt.day

test['Journey_Month'] = pd.to_datetime(test.Date_of_Journey,format = '%d/%m/%Y').dt.month

test = test.drop(['Date_of_Journey'],axis = 1)

test['dep_hour'] = pd.to_datetime(test['Dep_Time']).dt.hour

test['dep_min'] = pd.to_datetime(test['Dep_Time']).dt.minute

test = test.drop(['Dep_Time'], axis = 1)

test['Arrival_hour'] = pd.to_datetime(test['Arrival_Time']).dt.hour

test['Arrival_minute'] = pd.to_datetime(test['Arrival_Time']).dt.minute

test = test.drop(['Arrival_Time'], axis = 1)

#Dealing with Duration
duration = list(test['Duration'])

for i in range(len(duration)):
  if len(duration[i].split())!=2:
    if 'h' in duration[i]:
      duration[i] = duration[i].strip() +' 0m'
    else:
      duration[i] = '0h '+ duration[i]  
dur_hour = []
dur_min = [] 
for i in range(len(duration)):
  dur_hour.append(int(duration[i].split(sep = 'h')[0]))
  dur_min.append(int(duration[i].split(sep = 'm')[0].split()[-1]))

test['dur_hour'] = dur_hour
test['dur_min'] = dur_min

test = test.drop(['Duration'],axis = 1)

Airline = pd.get_dummies(test['Airline'], drop_first= True)
Source = test[['Source']]
Source = pd.get_dummies(Source, drop_first= True)
Destination = test[['Destination']]
Destination = pd.get_dummies(Destination, drop_first= True)
test = test.drop(['Route', 'Additional_Info'], axis = 1)

test.replace({'non-stop':0, '1 stop': 1, '2 stops': 2, '3 stops': 3, '4 stops': 4},inplace = True)

data_test = pd.concat([test,Airline,Source,Destination], axis = 1)
data_test.drop(['Airline','Source','Destination'],axis = 1, inplace= True)

data_test.head()

data_test.shape

x = data_train.copy()

x = x.drop(['Price'], axis = 1)

x.head()

y = data_train[['Price']]

y.head()

# Important feature using ExtraTreesRegressor

from sklearn.ensemble import ExtraTreesRegressor
selection = ExtraTreesRegressor()
selection.fit(x, y)

plt.figure(figsize = (12,8))
feat_importances = pd.Series(selection.feature_importances_, index=x.columns)
feat_importances.nlargest(20).plot(kind='barh')
plt.show()

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2, random_state = 6)

from sklearn.ensemble import RandomForestRegressor
rf = RandomForestRegressor()
rf.fit(x_train,y_train)

y_pred = rf.predict(x_test)

rf.score(x_train,y_train)

rf.score(x_test,y_test)

y_test.shape

y_pred.shape

y_pred = y_pred.reshape(-1,1)

sns.distplot(y_test - y_pred)

plt.scatter(y_test, y_pred, alpha = 0.5)
plt.xlabel("y_test")
plt.ylabel("y_pred")
plt.show()

from sklearn import metrics
print('MAE:', metrics.mean_absolute_error(y_test, y_pred))
print('MSE:', metrics.mean_squared_error(y_test, y_pred))
print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))

#HyperParameter tuning
n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]
max_depth = [int(x) for x in np.linspace(start = 5, stop = 30, num = 6)]
max_features = ['auto', 'sqrt']
min_samples_split = [2,5,10,20,50,100]
min_samples_leaf = [1,2,5,7,10]

from sklearn.model_selection import RandomizedSearchCV
random_grid = {'n_estimators':n_estimators,
               'max_depth':max_depth,
               'max_features':max_features,
               'min_samples_split':min_samples_split,
               'min_samples_leaf':min_samples_leaf}
print(random_grid)

rand_cv = RandomizedSearchCV(estimator = rf, param_distributions=random_grid, scoring= 'neg_mean_squared_error', cv = 10  )

rand_cv.fit(x_train, y_train)

rand_cv.best_params_

rf_regressor = RandomForestRegressor(n_estimators=1200,max_depth=15,min_samples_leaf=1,min_samples_split=2,max_features='sqrt')

rf_regressor.fit(x_train,y_train)

y_reg = rf_regressor.predict(x_test)

sns.distplot(y_test - y_reg)

y_reg = y_reg.reshape(-1,1)

from sklearn import metrics
print('MAE:', metrics.mean_absolute_error(y_test, y_reg))
print('MSE:', metrics.mean_squared_error(y_test, y_reg))
print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_reg)))

from sklearn.linear_model import LinearRegression
lr_regressor = LinearRegression()
lr_regressor.fit(x_train,y_train)

y_lr = lr_regressor.predict(x_test)
y_lr = y_lr.reshape(-1,1)

sns.distplot(y_test - y_lr)

print('MAE:', metrics.mean_absolute_error(y_test, y_lr))
print('MSE:', metrics.mean_squared_error(y_test, y_lr))
print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_lr)))

from sklearn.linear_model import Lasso
from sklearn.model_selection import GridSearchCV
lasso = Lasso()
parameters={'alpha':[1e-15,1e-10,1e-8,1e-3,1e-2,1,5,10,20,30,35,40]}
lasso_regressor=GridSearchCV(lasso,parameters,scoring='neg_mean_squared_error',cv=10)
lasso_regressor.fit(x_train,y_train)

y_lasso = lasso_regressor.predict(x_test)

y_lasso = y_lasso.reshape(-1,1)

sns.distplot(y_test - y_pred)

print('MAE:', metrics.mean_absolute_error(y_test, y_lasso))
print('MSE:', metrics.mean_squared_error(y_test, y_lasso))
print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_lasso)))

from xgboost import XGBRegressor
xg_reg = XGBRegressor()

#HyperParameter tuning
n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]
max_depth = [int(x) for x in np.linspace(start = 5, stop = 30, num = 6)]
learning_rate = [0.001,0.002,0.005,0.01,0.02,0.05,0.1,0.2,0.5]
from sklearn.model_selection import RandomizedSearchCV
random_grid = {'n_estimators':n_estimators,
               'max_depth':max_depth,
               'learning_rate':learning_rate}
print(random_grid)

rand_cv = RandomizedSearchCV(estimator = xg_reg, param_distributions=random_grid, scoring= 'neg_mean_squared_error', cv = 10  )

rand_cv.fit(x_train, y_train)

rand_cv.best_params_

xg_reggressor = XGBRegressor(max_depth=5,learning_rate=0.1,n_estimators=1000)

xg_reggressor.fit(x_train,y_train)

y_xg = xg_reggressor.predict(x_test)
y_xg = y_xg.reshape(-1,1)

sns.distplot(y_test - y_xg)

print('MAE:', metrics.mean_absolute_error(y_test, y_xg))
print('MSE:', metrics.mean_squared_error(y_test, y_xg))
print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_xg)))

from lightgbm import LGBMRegressor
lg_regressor = LGBMRegressor()

#HyperParameter tuning
n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]
max_depth = [-5,-3,-2,-1,1,3,5,8,15,20,25,30]
learning_rate = [0.001,0.002,0.005,0.01,0.02,0.05,0.1,0.2,0.5]
from sklearn.model_selection import RandomizedSearchCV
random_grid = {'n_estimators':n_estimators,
               'max_depth':max_depth,
               'learning_rate':learning_rate}
print(random_grid)

rand_cv = RandomizedSearchCV(estimator = lg_regressor, param_distributions=random_grid, scoring= 'neg_mean_squared_error', cv = 10  )

rand_cv.fit(x_train, y_train)

lg_regressor.fit(x_train,y_train)

y_lg = lg_regressor.predict(x_test)
y_lg = y_lg.reshape(-1,1)

sns.distplot(y_test - y_lg)

print('MAE:', metrics.mean_absolute_error(y_test, y_lg))
print('MSE:', metrics.mean_squared_error(y_test, y_lg))
print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_lg)))

# Creating a pickle file for the classifier
import pickle
filename = 'flight-fare-prediction-model.pkl'
pickle.dump(rf, open(filename, 'wb'))



















